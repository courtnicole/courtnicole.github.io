---
import DefaultLayout from "../layouts/DefaultLayout.astro";
import midair from '../assets/images/midair_1.webp';
import cognition from '../assets/images/vr_cognition.webp';
import arcade from '../assets/images/arcade_1.webp';
import remind from '../assets/images/remind_1.webp';
import rdw from '../assets/images/rdw_1.webp';
import ContentMedia from "../components/ContentMedia.astro";
---

<DefaultLayout title="Research">
  <section class="my-12">
    <div class="container">
      <h1>Selected Research</h1>
      <ContentMedia
        imgSrc={midair}
        title="Mid-Air Locomotion & Spatial Cognition"
        tags="SPATIAL COGNITION  //  LOCOMOTION"
        showLink={false}
        altText="In Progress"
      >
        I am using eye tracking data to assess the cognitive workload of one-handed and two-handed path creation techniques, and to estimate the cognitive workload of mid-air locomotion techniques with varying degrees of freedom. To ensure accurate pupillometry data, I calculate the luminosity of the scene in real-time on compute. I then use an individualized pupillary light reflex (PLR) function to correct for PLR responses to the luminosity of the scene.
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={cognition}
        title="3D User Interfaces for Mixed Reality Path Planning"
        tags="SPATIAL COGNITION  //  3D  INTERACTION"
        showLink=true
        url="https://doi.org/10.3389/frvir.2023.1192757"
      >
      In two user studies, I explored intuitive methods for creating intricate 3D paths in augmented and virtual reality. It details the design of 3D user interfaces for novice users, and the efficacy of one-handed and two-handed manipulation techniques for path creation. The findings highlight the potential of these spatially situated interaction metaphors for path-driven tasks across animation, architecture, robotics and more.
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={arcade}
        title="VR Arcade Game"
        tags="PERSONAL PROJECTS  //  3D  INTERACTION"
        showLink={false}
        altText=""
      >
        This began as an experimentation with different locomotion techniques and reference frames for virtual reality, and developed into a riff on the classic Pac-Man arcade game. It was implemented in Unity with OpenXR for both Vive and Oculus devices. All of the interactions were implemented from the ground up for flexibility.
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={remind}
        title="ReMind: Wearable for Emotional Awareness"
        tags="EMBODIED INTERACTION  //  COMMUNITY-DRIVEN DESIGN"
        url="https://doi.org/10.1145/3290607.3312997"
        linkText="View Paper"
      >
      Through a participatory design process, this research examined the challenges faced during the later stages of recovery and developed a wearable prototype, ReMind, to meet the communityâ€™s needs surrounding emotion regulation and emotional awareness.   
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={rdw}
        title="Individualized Rotation Gains for Redirected Walking"
        tags="LOCOMOTION   //  PSYCHOPHYSICAL THRESHOLDS"
        url="https://doi.org/10.2312/egve.20181315"
        linkText="View Paper"
      >
       This work implements two psychophysical algorithms for threshold detection and investigates their accuracy for calculating individualized rotation gain thresholds for redirected walking. These methods require less than 3m x 3m of physical space and under 5 minutes of time to complete. Both methods proved viable, however, the PEST algorithm was found to be the most accurate and efficient for calculating these thresholds. 
      </ContentMedia>
    </div>
  </section>
</DefaultLayout>
