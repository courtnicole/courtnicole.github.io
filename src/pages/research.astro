---
import DefaultLayout from "../layouts/DefaultLayout.astro";
import midair from '../assets/images/midair_1.webp';
import cognition from '../assets/images/vr_cognition.webp';
import arcade from '../assets/images/arcade_1.webp';
import remind from '../assets/images/remind_1.webp';
import rdw from '../assets/images/rdw_1.webp';
import ContentMedia from "../components/ContentMedia.astro";
---

<DefaultLayout title="Research">
  <section class="my-12">
    <div class="container">
      <h1>Selected Research</h1>
      <ContentMedia
        imgSrc={midair}
        title="Mid-Air Locomotion & Spatial Cognition"
        tags="SPATIAL COGNITION  //  LOCOMOTION"
        showLink={false}
        altText="Under Review"
      >
        I am using eye tracking data to assess the cognitive workload of one-handed and two-handed path creation techniques, and to estimate the cognitive workload of mid-air locomotion techniques with varying degrees of freedom. To ensure accurate pupillometry data, I calculate the luminosity of the HMD in real-time on compute, then use an individualized pupillary light reflex (PLR) function to correct for this response.
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={cognition}
        title="3D User Interfaces for Mixed Reality Path Planning"
        tags="SPATIAL COGNITION  //  3D  INTERACTION"
        showLink=true
        url="https://doi.org/10.3389/frvir.2023.1192757"
      >
      In two user studies, I explored intuitive methods for creating intricate 3D paths in complex spaces for augmented and virtual reality. I designed multiple 3D user interfaces for novice users, and examined the efficacy and learnability of one-handed and two-handed techniques using quantitative metrics adapted from 2D user interface research. 
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={arcade}
        title="VR Arcade Game"
        tags="PERSONAL PROJECTS  //  3D  INTERACTION"
        showLink={false}
        altText=""
      >
        This began as an experimentation with different locomotion techniques and reference frames for virtual reality, and developed into a riff on the classic Pac-Man arcade game. I developed it in Unity with OpenXR for both Vive and Oculus devices. All of the interactions were implemented from the ground up for flexibility.
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={remind}
        title="ReMind: Wearable for Emotional Awareness"
        tags="EMBODIED INTERACTION  //  COMMUNITY-DRIVEN DESIGN"
        url="https://doi.org/10.1145/3290607.3312997"
        linkText="View Paper"
      >
      Through a participatory design process, I examined the challenges faced during the later stages of addiction recovery and developed a wearable prototype, ReMind, to help develop emotional awareness and literacy.    
      </ContentMedia>
      <hr class="h-px my-2 bg-gray-200 border-0 dark:bg-gray-700" />
      <ContentMedia
        imgSrc={rdw}
        title="Individualized Rotation Gains for Redirected Walking"
        tags="LOCOMOTION   //  PSYCHOPHYSICAL THRESHOLDS"
        url="https://doi.org/10.2312/egve.20181315"
        linkText="View Paper"
      >
       I implemented and tested two psychophysical algorithms for threshold detection, and investigated their accuracy for calculating individualized rotation gain thresholds for redirected walking. These methods require less than 3m x 3m of physical space and under 5 minutes of time to complete. Both methods proved viable, however, the PEST algorithm was the most accurate and efficient. 
      </ContentMedia>
    </div>
  </section>
</DefaultLayout>
